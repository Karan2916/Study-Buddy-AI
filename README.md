üìñ Study Buddy AI: RAG Assistant for CourseworkAn intelligent, Retrieval-Augmented Generation (RAG) based chatbot designed to help students at BMSCE query and understand their course materials. Upload your PDFs and get instant, accurate answers with citations and relevant learning resources.Live Demo: https://study-buddy-frontend-ycrk.onrender.com(Suggestion: Replace this placeholder with a real screenshot of your application)üöÄ Project OverviewBMSCE students often juggle dozens of PDFs, lecture notes, and textbooks, making it difficult to find specific information, especially during exam preparation. Study Buddy AI solves this by creating a centralized, searchable knowledge base from your course documents.Using a powerful RAG pipeline, the application combines fast semantic search (FAISS) with a large language model (Google's Gemini) to provide concise, context-aware answers. It cites the exact page number from your documents and even suggests relevant YouTube videos to enhance your learning, directly addressing the core challenges of modern, digital-first education.‚ú® Key FeaturesüìÑ PDF Document Indexing: Upload multiple course notes, slides, and textbooks to build your personal knowledge base at runtime.ü§ñ AI-Powered Q&A: Ask complex questions in natural language and get accurate answers generated by an AI agent.üìö Source Citations: Every answer includes a citation with the specific page number from the source document, ensuring trust and explainability.üì∫ YouTube Integration: Automatically finds and displays a relevant YouTube video with a clickable thumbnail for each topic you ask about.üõ°Ô∏è Content Guardrails: Implements safety settings to handle harmful or abusive queries appropriately.üí° Innovative Prompt Engineering: The system prompt is personalized for the BMSCE curriculum, guiding the AI to act as a helpful tutor.üõ†Ô∏è Tech StackThis project is a full-stack application built with a modern, open-source technology stack, fulfilling the project's constraints.ComponentTechnology/LibraryDescriptionFrontendReact, TypeScript, ViteA modern, fast, and type-safe web application.shadcn/ui, Tailwind CSSFor building a beautiful and accessible component-based UI.AxiosFor making robust API calls to the backend.BackendPython 3.10+, FastAPIA high-performance asynchronous API framework.Google Generative AIPowers the core AI agent using the Gemini 1.5 Pro model.LangChainUsed for document processing, chunking, and embeddings.FAISS (Facebook AI)For creating an efficient, local vector database for semantic search.DeploymentRenderFor hosting the backend (Web Service) and frontend (Static Site).‚öôÔ∏è Getting Started: Running LocallyTo run this project on your local machine, follow these steps.PrerequisitesNode.js and npm (or Bun/Yarn)Python 3.10+ and pipGit1. Clone the Repositorygit clone https://github.com/Karan2916/Study-Buddy-AI.git
cd Study-Buddy-AI
2. Set Up the BackendNavigate to the backend folder:cd backend
Create and activate a virtual environment:python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
Install Python dependencies:pip install -r requirements.txt
Create your environment file:Create a file named .env inside the backend folder.Add your secret keys to this file:GOOGLE_API_KEY="your_gemini_api_key"
GOOGLE_CUSTOM_SEARCH_API_KEY="your_custom_search_api_key"
GOOGLE_SEARCH_ENGINE_ID="your_search_engine_id"
3. Set Up the FrontendNavigate to the frontend folder:cd ../frontend
Install Node.js dependencies:npm install
Create your environment file:Create a file named .env inside the frontend folder.Add the following line to point to your local backend server:VITE_API_URL=http://localhost:8000
4. Run the ApplicationYou'll need two separate terminals running at the same time.Terminal 1 (Backend): In the backend folder, run:uvicorn main:app --reload
Terminal 2 (Frontend): In the frontend folder, run:npm run dev
Open your browser to http://localhost:5173 (or the URL provided by Vite) to use the application.üöÄ DeploymentThis application is deployed on Render using a monorepo structure.The backend is deployed as a Web Service.The frontend is deployed as a Static Site, which communicates with the live backend via an environment variable.Changes pushed to the main branch will automatically trigger new deployments on Render.üîÆ Future ImprovementsRe-ranking: Implement a cross-encoder model (e.g., from Cohere) to re-rank the retrieved documents for even higher precision.Evaluation Dashboard: Build a simple UI to display RAGAS evaluation metrics, measuring faithfulness, context precision, and recall.Conversation History: Add the ability to save and load previous chat sessions.Feel free to contribute to this project by submitting a pull request.
